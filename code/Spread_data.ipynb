{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "The following code was a test try to get spread data of a given bond list alongside some simplier spread data. The code worked but took very long to run so we opted to focus more on price data as we could collect this more easily rather than bid and ask data.\n",
        "\n",
        "The code is structured in the following way:\n",
        "- Setup with Packages & Functions\n",
        "- Spread data webscraping for bonds by first extracting all the bond links (links to the bond specific website on the frankfurt exchange)\n",
        "- Then code to loop through all these links and extract the bond data using multiple instances of selenium to speed up the process\n",
        "\n",
        "Note: This code is very similar to the static data code, just focussing on the bid and ask prices"
      ],
      "metadata": {
        "id": "Ej6lOyv-KW-l"
      },
      "id": "Ej6lOyv-KW-l"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Packages & Function to Get Data (RUN FIRST)"
      ],
      "metadata": {
        "id": "H1vyzv_pG95N"
      },
      "id": "H1vyzv_pG95N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7e1e656-7aed-46b0-b12a-f89abecbe24b",
      "metadata": {
        "id": "d7e1e656-7aed-46b0-b12a-f89abecbe24b"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade selenium\n",
        "!apt update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c5e76df-7d73-497e-be0e-fecf1e3bfd3e",
      "metadata": {
        "id": "7c5e76df-7d73-497e-be0e-fecf1e3bfd3e"
      },
      "outputs": [],
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import NoSuchElementException  # Ensure this is imported\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "import csv\n",
        "import time\n",
        "import shutil\n",
        "import re\n",
        "import pandas as pd\n",
        "from selenium.common.exceptions import TimeoutException"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e60e5b5-b743-4a32-8e7d-0ea3356e9762",
      "metadata": {
        "id": "6e60e5b5-b743-4a32-8e7d-0ea3356e9762"
      },
      "outputs": [],
      "source": [
        "def extract_bond_links(soup):\n",
        "    bond_table = soup.find(\"div\", {\"class\": \"table-responsive\"})\n",
        "    links = []\n",
        "    if bond_table:\n",
        "        rows = bond_table.find_all(\"tr\")\n",
        "        for row in rows:\n",
        "            cols = row.find_all(\"td\")\n",
        "            if len(cols) >= 1:\n",
        "                link_element = cols[0].find(\"a\", href=True)\n",
        "                if link_element:\n",
        "                    links.append(link_element[\"href\"])\n",
        "    return links\n",
        "\n",
        "def extract_bond_data(driver, url):\n",
        "    # Open the bond detail page\n",
        "    driver.get(url)\n",
        "    bond_data = {\"URL\": url}  # Start with URL for traceability\n",
        "\n",
        "    try:\n",
        "        # Handle cookie banner if it appears\n",
        "        try:\n",
        "            cookie_button = WebDriverWait(driver, 10).until(\n",
        "                EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Decline')]\"))\n",
        "            )\n",
        "            cookie_button.click()\n",
        "            print(\"Cookie banner handled successfully (Declined).\")\n",
        "        except TimeoutException:\n",
        "            print(\"Cookie banner not found. Skipping...\")\n",
        "\n",
        "        # Wait for the data table to load\n",
        "        WebDriverWait(driver, 10).until(\n",
        "            EC.presence_of_element_located((By.XPATH, \"//div[@_ngcontent-boerse-frankfurt-c151]\"))\n",
        "        )\n",
        "\n",
        "        # Define the data points and their XPaths\n",
        "        data_points = {\n",
        "            \"time\": \"//div[@_ngcontent-boerse-frankfurt-c151]//td[contains(@class, 'widget-table-cell text-right') and text()[contains(., ':')]]\",\n",
        "            \"bid\": \"//div[@_ngcontent-boerse-frankfurt-c151]//td[contains(@class, 'widget-table-cell askBidLimit') and not(contains(@class, 'text-right'))]\",\n",
        "            \"ask\": \"//div[@_ngcontent-boerse-frankfurt-c151]//td[contains(@class, 'widget-table-cell askBidLimit text-right')]\",\n",
        "            \"bid_for_x_nominal\": \"//div[@_ngcontent-boerse-frankfurt-c151]//td[contains(@class, 'widget-table-cell') and text()[contains(., 'für')] and not(contains(@class, 'text-right'))]\",\n",
        "            \"ask_for_x_nominal\": \"//div[@_ngcontent-boerse-frankfurt-c151]//td[contains(@class, 'widget-table-cell text-right') and text()[contains(., 'für')] and not(contains(@class, 'border-bottom'))]\",\n",
        "            \"difference_to_day_before\": \"//div[@_ngcontent-boerse-frankfurt-c151]//td[contains(@class, 'widget-table-cell border-bottom text-right') and (contains(@class, 'text-color-green') or contains(@class, 'text-color-red'))]\",\n",
        "            \"spread_absolute_relative\": \"//div[@_ngcontent-boerse-frankfurt-c151]//td[contains(@class, 'widget-table-cell no-border text-right')]\"\n",
        "        }\n",
        "\n",
        "        # Loop through each data point and extract the text\n",
        "        for key, xpath in data_points.items():\n",
        "            try:\n",
        "                # Use find_elements to handle multiple matches and select the first one\n",
        "                elements = driver.find_elements(By.XPATH, xpath)\n",
        "                if elements:\n",
        "                    text = elements[0].text.strip()  # Get the first element's text\n",
        "                    if key in [\"bid_for_x_nominal\", \"ask_for_x_nominal\"]:\n",
        "                        match = re.search(r'\\d+', text)  # Extract only the numeric value\n",
        "                        bond_data[key] = int(match.group()) if match else 0  # Default to 0 if no number is found\n",
        "                    else:\n",
        "                        bond_data[key] = text  # Save the full text for other fields\n",
        "                else:\n",
        "                    bond_data[key] = \"N/A\"  # Handle missing elements gracefully\n",
        "\n",
        "            except Exception as inner_e:\n",
        "                bond_data[key] = \"N/A\"  # Handle missing data gracefully\n",
        "                print(f\"Error extracting data for {key}: {inner_e}\")\n",
        "\n",
        "    except TimeoutException:\n",
        "        print(f\"Timeout: Failed to load data on page {url}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing {url}: {e}\")\n",
        "\n",
        "    return bond_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code to extract all bond links from the Frankfurter Boerse"
      ],
      "metadata": {
        "id": "Q7SjvJYUHASe"
      },
      "id": "Q7SjvJYUHASe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7ea813a-2d1f-40ca-baea-07e421862f82",
      "metadata": {
        "id": "b7ea813a-2d1f-40ca-baea-07e421862f82"
      },
      "outputs": [],
      "source": [
        "# Check if Chromedriver is available on system path\n",
        "shutil.which(\"chromedriver\")\n",
        "\n",
        "# Set up Chrome options to run in headless mode\n",
        "chrome_options = Options()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "# Initialize the Selenium WebDriver with the options\n",
        "driver = webdriver.Chrome(options=chrome_options)  # Or use webdriver.Firefox(), etc.\n",
        "\n",
        "# URL to scrape\n",
        "url = \"https://www.boerse-frankfurt.de/anleihen/most-traded\"\n",
        "\n",
        "# Script principal\n",
        "try:\n",
        "    # start driver\n",
        "    driver.get(url)\n",
        "    wait = WebDriverWait(driver, 5)\n",
        "\n",
        "    try:\n",
        "        cookie_button = WebDriverWait(driver, 5).until(\n",
        "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Decline')]\"))\n",
        "        )\n",
        "        cookie_button.click()\n",
        "        print(\"Cookie banner handled successfully (Declined).\")\n",
        "    except TimeoutException:\n",
        "        print(\"Cookie banner not found. Skipping...\")\n",
        "\n",
        "    # 100 button\n",
        "    hundred_button = wait.until(\n",
        "        EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'page-bar-type-button btn btn-lg ng-star-inserted') and text()='100']\"))\n",
        "    )\n",
        "    hundred_button.click()\n",
        "    time.sleep(5)\n",
        "\n",
        "    # Variable to store bond links\n",
        "    all_bond_links = []\n",
        "    # Get total number of pages\n",
        "    page_buttons = driver.find_elements(\n",
        "        By.XPATH,\n",
        "        \"//button[contains(@class, 'page-bar-type-button page-bar-type-button-width-auto btn btn-lg ng-star-inserted') and not(@disabled)]\",\n",
        "    )\n",
        "    page_limit = 10 # Limit to 1000 bonds for now\n",
        "    total_pages = min(\n",
        "        int(page_buttons[-1].text.strip()), page_limit or float(\"inf\")\n",
        "    )\n",
        "    print(f\"Total pages varaible: {total_pages}\")\n",
        "    print(f\"Total pages shown on website: {page_buttons[-1].text.strip()}\")\n",
        "\n",
        "    for page in range(1, total_pages + 1):\n",
        "        try:\n",
        "            if page != 1:\n",
        "                page_button = wait.until(\n",
        "                    EC.element_to_be_clickable((By.XPATH, f\"//button[contains(@class, 'page-bar-type-button page-bar-type-button-width-auto btn btn-lg ng-star-inserted') and text()='{page}']\"))\n",
        "                )\n",
        "                page_button.click()\n",
        "                time.sleep(5)\n",
        "\n",
        "            page_source = driver.page_source\n",
        "            soup = BeautifulSoup(page_source, \"html.parser\")\n",
        "            bond_links = extract_bond_links(soup)\n",
        "            all_bond_links.extend(bond_links)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error at the page {page}: {e}\")\n",
        "            break\n",
        "\n",
        "    # Collecter les static data pour chaque obligation\n",
        "    detailed_bonds_data = []\n",
        "    print(f\"preview of bond links: {all_bond_links}\")\n",
        "\n",
        "    # getting bond data now\n",
        "    # Base URL\n",
        "    base_url = \"https://www.boerse-frankfurt.de\"\n",
        "\n",
        "    # # Iterate through each bond link\n",
        "    # for link in all_bonds_links:  # `all_bonds_links` should already be collected earlier\n",
        "    #     full_url = base_url + link\n",
        "    #     print(f\"Processing bond URL: {full_url}\")\n",
        "    #     bond_data = extract_bond_data(driver, full_url)\n",
        "    #     detailed_bonds_data.append(bond_data)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Critical error: {e}\")\n",
        "    # add screenshot\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    screenshot_path = f\"error_screenshot_{timestamp}.png\"\n",
        "    driver.save_screenshot(screenshot_path)\n",
        "\n",
        "# Export the DataFrame to a CSV file even if errors occur\n",
        "finally:\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    # # Create a DataFrame from the data\n",
        "    # df = pd.DataFrame(detailed_bonds_data)\n",
        "    # # Save to CSV\n",
        "    # csv_file = f\"bond_spread_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "    # df.to_csv(csv_file, index=False)\n",
        "    # print(f\"Data saved to {csv_file}\")\n",
        "\n",
        "    # Save bond links as a backup\n",
        "    df_links = pd.DataFrame(all_bond_links, columns=[\"Bond Links\"])\n",
        "    csv_links_file = f\"bond_links_backup_{timestamp}.csv\"\n",
        "    df_links.to_csv(csv_links_file, index=False)\n",
        "    print(f\"Bond links backup saved to {csv_links_file}\")\n",
        "\n",
        "    # Close the WebDriver\n",
        "    driver.quit()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After getting a list of all the bonds listed on the Frankfurter Boerse and the respective links to all the bond's websites, we can pass these links to the spread data webscraping code below to extract the spread data for only the links specified there"
      ],
      "metadata": {
        "id": "mTdf0wpPLkrt"
      },
      "id": "mTdf0wpPLkrt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spread data Webscraping based on provided bond links"
      ],
      "metadata": {
        "id": "q1HZoa_yLeWI"
      },
      "id": "q1HZoa_yLeWI"
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "\n",
        "# declare but don't define the driver yet\n",
        "driver = None\n",
        "base_url = \"https://www.boerse-frankfurt.de\"\n",
        "\n",
        "def create_driver():\n",
        "    global driver # let this function set the driver globally\n",
        "    # Check if Chromedriver is available on system path\n",
        "    shutil.which(\"chromedriver\")\n",
        "    chrome_options = Options()\n",
        "    chrome_options.add_argument('--headless')\n",
        "    chrome_options.add_argument('--no-sandbox')\n",
        "    chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "\n",
        "    # Initialize the Selenium WebDriver with the options\n",
        "    driver = webdriver.Chrome(options=chrome_options)  # Or use webdriver.Firefox(), etc.\n",
        "\n",
        "    # don't return anything\n",
        "\n",
        "urls = all_bond_links # your list of urls\n",
        "\n",
        "# number of processes to use\n",
        "# can be more than the number of CPUs\n",
        "num_concurrent = 10\n",
        "\n",
        "def scrape(link):\n",
        "    assert driver is not None, \"Driver not set up inside process\"\n",
        "    # Iterate through each bond link\n",
        "    full_url = base_url + link\n",
        "    print(f\"Processing bond URL: {full_url}\")\n",
        "    bond_data = extract_bond_data(driver, full_url)\n",
        "    return bond_data\n",
        "\n",
        "with Pool(num_concurrent, initializer=create_driver) as p:\n",
        "    detailed_bonds_data = p.map(scrape, urls)\n",
        "\n",
        "df = pd.DataFrame(detailed_bonds_data)\n",
        "# Save to CSV\n",
        "csv_file = f\"bond_spread_data_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        "df.to_csv(csv_file, index=False)\n",
        "print(f\"Data saved to {csv_file}\")"
      ],
      "metadata": {
        "id": "oWaWKcDkeVUt",
        "collapsed": true
      },
      "id": "oWaWKcDkeVUt",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}