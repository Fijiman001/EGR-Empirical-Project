{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fijiman001/EGR-Empirical-Project/blob/main/code/static_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1d8259c-d742-42f9-bbc8-54368a746720",
      "metadata": {
        "id": "e1d8259c-d742-42f9-bbc8-54368a746720"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade selenium\n",
        "!apt update\n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "\n",
        "\"\"\"# Packages & Function to Get Data\"\"\"\n",
        "\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import NoSuchElementException  # Ensure this is imported\n",
        "from bs4 import BeautifulSoup\n",
        "from datetime import datetime\n",
        "import csv\n",
        "import time\n",
        "import shutil\n",
        "import os\n",
        "from multiprocessing import Pool\n",
        "import re\n",
        "import pandas as pd\n",
        "from selenium.common.exceptions import TimeoutException\n",
        "import requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd7a2cbf-1015-48b5-89a9-68c01eb485ea",
      "metadata": {
        "id": "cd7a2cbf-1015-48b5-89a9-68c01eb485ea"
      },
      "outputs": [],
      "source": [
        "def extract_bond_links(soup):\n",
        "    bond_table = soup.find(\"div\", {\"class\": \"table-responsive\"})\n",
        "    links = []\n",
        "    if bond_table:\n",
        "        rows = bond_table.find_all(\"tr\")\n",
        "        for row in rows:\n",
        "            cols = row.find_all(\"td\")\n",
        "            if len(cols) >= 1:\n",
        "                link_element = cols[0].find(\"a\", href=True)\n",
        "                if link_element:\n",
        "                    links.append(link_element[\"href\"])\n",
        "    return links\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def separate_text(df):\n",
        "\n",
        "    text = df\n",
        "    # Regular expression to split by commas, except when inside single quotes\n",
        "    pattern = r\"(?<!\\\\)',(?!')\"\n",
        "\n",
        "    # Split the text by commas, respecting quotes\n",
        "    separated_list = re.split(pattern, text)\n",
        "\n",
        "    # Clean up: Remove extra spaces and quotes\n",
        "    separated_list = [item.strip().strip(\"'\") for item in separated_list]\n",
        "\n",
        "    return separated_list\n",
        "\n",
        "def format_value(value):\n",
        "    # Helper function to format values as needed (e.g., percentages, empty strings, etc.)\n",
        "    if value is None or value == '':\n",
        "        return None\n",
        "    # Handle percentage formatting\n",
        "    if \"%\" in value:\n",
        "        return value.replace(\",\", \".\")  # Convert to decimal format\n",
        "    return value\n",
        "\n",
        "def process_bond_dataframe(df):\n",
        "    processed_data = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        # Extract the raw data\n",
        "        raw_data = row[\"//div[@_ngcontent-boerse-frankfurt-c174]//td[contains(@class, 'widget-table-cell')]\"]\n",
        "\n",
        "        # Ensure the data is cleaned and in list format\n",
        "        if isinstance(raw_data, list):\n",
        "            cleaned_data = [entry.strip() for entry in raw_data if entry.strip()]\n",
        "        else:\n",
        "            print(f\"Row {index} has invalid data format. Skipping.\")\n",
        "            continue\n",
        "\n",
        "        # Directly map the cleaned data to columns\n",
        "        row_data = {f\"column_{i}\": format_value(value) for i, value in enumerate(cleaned_data)}\n",
        "\n",
        "        # Add the URL for traceability\n",
        "        row_data[\"URL\"] = row[\"URL\"]\n",
        "\n",
        "        # Append the row data\n",
        "        processed_data.append(row_data)\n",
        "\n",
        "    # Create a DataFrame from the processed data\n",
        "    processed_df = pd.DataFrame(processed_data)\n",
        "    return processed_df\n",
        "\n",
        "\n",
        "def extract_bond_data(driver, url):\n",
        "    # Open the bond detail page\n",
        "    driver.get(url)\n",
        "    bond_data = {\"URL\": url}  # Start with URL for traceability\n",
        "\n",
        "    try:\n",
        "        # Cookie Handler\n",
        "        try:\n",
        "            wait = WebDriverWait(driver, 5)\n",
        "            cookie_button = wait.until(\n",
        "                EC.element_to_be_clickable((By.ID, \"cookie-hint-btn-decline\"))\n",
        "            )\n",
        "            cookie_button.click()\n",
        "            # print(\"Cookie banner handled successfully (Declined).\")\n",
        "        except TimeoutException:\n",
        "            # print(\"Cookie banner not found. Skipping...\")\n",
        "            None\n",
        "        try:\n",
        "            wait.until(\n",
        "                EC.invisibility_of_element_located((By.CSS_SELECTOR, \".wrapper[_ngcontent-boerse-frankfurt-c97]\"))\n",
        "            )\n",
        "            # print(\"Overlay disappeared before 100 button\")\n",
        "\n",
        "            wait.until(\n",
        "                EC.invisibility_of_element_located((By.CSS_SELECTOR, \".wrapper[_ngcontent-boerse-frankfurt-c98]\"))\n",
        "            )\n",
        "            # print(\"Overlay c98 disappeared - Loading Table element\")\n",
        "        except TimeoutException:\n",
        "            print(\" Table did not load fully\")\n",
        "            driver.save_screenshot(f\"error_loading_initial_table.png\") # test\n",
        "\n",
        "        # Wait for the data table to load\n",
        "        wait.until(\n",
        "            EC.presence_of_element_located((By.XPATH, \"//div[@_ngcontent-boerse-frankfurt-c174]\"))\n",
        "        )\n",
        "\n",
        "        # To ensure we get static Data\n",
        "        time.sleep(2)\n",
        "\n",
        "        # Define the data points and their XPaths\n",
        "        data_points = [\n",
        "            \"//div[@_ngcontent-boerse-frankfurt-c174]//td[contains(@class, 'widget-table-cell')]\",\n",
        "            \"//div[@_ngcontent-boerse-frankfurt-c174]//td[contains(@class, 'widget-table-cell text-right')]\"\n",
        "        ]\n",
        "\n",
        "        # Loop through each XPath in data_points and extract the text\n",
        "        for xpath in data_points:\n",
        "            try:\n",
        "                # Use find_elements to handle multiple matches and extract all values\n",
        "                elements = driver.find_elements(By.XPATH, xpath)\n",
        "                if elements:\n",
        "                    # Extract and clean the text from all matched elements\n",
        "                    extracted_values = [element.text.strip() for element in elements]\n",
        "                    bond_data[xpath] = extracted_values  # Save all extracted values under the XPath as the key\n",
        "                else:\n",
        "                    bond_data[xpath] = []  # Handle missing elements with an empty list\n",
        "\n",
        "            except Exception as inner_e:\n",
        "                bond_data[xpath] = []  # Handle missing data gracefully\n",
        "                print(f\"Error extracting data for XPath {xpath}: {inner_e}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing {url}: {e}\")\n",
        "\n",
        "    return bond_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Static Data for bonds"
      ],
      "metadata": {
        "id": "xFDFhNkXJUZD"
      },
      "id": "xFDFhNkXJUZD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a7ab02bf-5720-44db-8dc5-0102cebfc70b",
      "metadata": {
        "id": "a7ab02bf-5720-44db-8dc5-0102cebfc70b",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "# Check if Chromedriver is available on system path\n",
        "shutil.which(\"chromedriver\")\n",
        "\n",
        "# Configuration de Selenium WebDriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument(\"--headless\")\n",
        "options.add_argument(\"--no-sandbox\")\n",
        "options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "# Initialisation de driver\n",
        "driver = webdriver.Chrome(options=options)\n",
        "url = \"https://www.boerse-frankfurt.de/anleihen/most-traded\"\n",
        "# url = \"https://www.boerse-frankfurt.de/anleihen/green-bonds\"\n",
        "\n",
        "# Script principal\n",
        "try:\n",
        "    # start driver\n",
        "    driver.get(url)\n",
        "    wait = WebDriverWait(driver, 5)\n",
        "\n",
        "    try:\n",
        "        cookie_button = WebDriverWait(driver, 5).until(\n",
        "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Decline')]\"))\n",
        "        )\n",
        "        cookie_button.click()\n",
        "        print(\"Cookie banner handled successfully (Declined).\")\n",
        "    except TimeoutException:\n",
        "        print(\"Cookie banner not found. Skipping...\")\n",
        "\n",
        "    # 100 button\n",
        "    hundred_button = wait.until(\n",
        "        EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'page-bar-type-button btn btn-lg ng-star-inserted') and text()='100']\"))\n",
        "    )\n",
        "    hundred_button.click()\n",
        "    time.sleep(5)\n",
        "\n",
        "    # Variable to store bond links\n",
        "    all_bond_links = []\n",
        "    # Get total number of pages\n",
        "    page_buttons = driver.find_elements(\n",
        "        By.XPATH,\n",
        "        \"//button[contains(@class, 'page-bar-type-button page-bar-type-button-width-auto btn btn-lg ng-star-inserted') and not(@disabled)]\",\n",
        "    )\n",
        "    page_limit = 2 # Limit to 1000 bonds for now\n",
        "    total_pages = min(\n",
        "        int(page_buttons[-1].text.strip()), page_limit or float(\"inf\")\n",
        "    )\n",
        "    print(f\"Total pages varaible: {total_pages}\")\n",
        "    print(f\"Total pages shown on website: {page_buttons[-1].text.strip()}\")\n",
        "\n",
        "    for page in range(1, total_pages + 1):\n",
        "        try:\n",
        "            if page != 1:\n",
        "                page_button = wait.until(\n",
        "                    EC.element_to_be_clickable((By.XPATH, f\"//button[contains(@class, 'page-bar-type-button page-bar-type-button-width-auto btn btn-lg ng-star-inserted') and text()='{page}']\"))\n",
        "                )\n",
        "                page_button.click()\n",
        "                time.sleep(5)\n",
        "\n",
        "            page_source = driver.page_source\n",
        "            soup = BeautifulSoup(page_source, \"html.parser\")\n",
        "            bond_links = extract_bond_links(soup)\n",
        "            all_bond_links.extend(bond_links)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error at the page {page}: {e}\")\n",
        "            break\n",
        "\n",
        "    # Collecter les static data pour chaque obligation\n",
        "    static_bonds_data = []\n",
        "    print(f\"preview of bond links: {all_bond_links}\")\n",
        "\n",
        "    # getting bond data now\n",
        "    # Base URL\n",
        "    base_url = \"https://www.boerse-frankfurt.de\"\n",
        "\n",
        "    # Iterate through each bond link\n",
        "    for link in all_bond_links[:1000]:  # all_bonds_links should already be collected earlier\n",
        "        full_url = base_url + link\n",
        "        print(f\"Processing bond URL: {full_url}\")\n",
        "        bond_data = extract_bond_data(driver, full_url)\n",
        "        static_bonds_data.append(bond_data)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Critical error: {e}\")\n",
        "    # add screenshot\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    screenshot_path = f\"error_screenshot_{timestamp}.png\"\n",
        "    driver.save_screenshot(screenshot_path)\n",
        "\n",
        "# Export the DataFrame to a CSV file even if errors occur\n",
        "finally:\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    # Close the WebDriver\n",
        "    # save data\n",
        "    df = pd.DataFrame(static_bonds_data)\n",
        "    processed_df = process_bond_dataframe(df)\n",
        "    csv_file = f\"Static_bond_data{timestamp}.csv\"\n",
        "    processed_df.to_csv(csv_file, index=False)\n",
        "    df.to_csv(\"raw_static_data.csv\", index=False)\n",
        "    print(f\"Data saved to {csv_file}\")\n",
        "    driver.quit()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_df"
      ],
      "metadata": {
        "collapsed": true,
        "id": "KPLEgY1nZ09Y"
      },
      "id": "KPLEgY1nZ09Y",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extracting only bond links from all pages"
      ],
      "metadata": {
        "id": "tcxbq29DI2bi"
      },
      "id": "tcxbq29DI2bi"
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if Chromedriver is available on system path\n",
        "shutil.which(\"chromedriver\")\n",
        "\n",
        "# Configuration de Selenium WebDriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument(\"--headless\")\n",
        "options.add_argument(\"--no-sandbox\")\n",
        "options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "# Initialisation de driver\n",
        "driver = webdriver.Chrome(options=options)\n",
        "url = \"https://www.boerse-frankfurt.de/anleihen/most-traded\"\n",
        "# url = \"https://www.boerse-frankfurt.de/anleihen/green-bonds\"\n",
        "\n",
        "# Script principal\n",
        "try:\n",
        "    # start driver\n",
        "    driver.get(url)\n",
        "    wait = WebDriverWait(driver, 10)\n",
        "\n",
        "    try:\n",
        "        cookie_button = WebDriverWait(driver, 5).until(\n",
        "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Decline')]\"))\n",
        "        )\n",
        "        cookie_button.click()\n",
        "        print(\"Cookie banner handled successfully (Declined).\")\n",
        "    except TimeoutException:\n",
        "        print(\"Cookie banner not found. Skipping...\")\n",
        "\n",
        "    # 100 button\n",
        "    hundred_button = wait.until(\n",
        "        EC.element_to_be_clickable((By.XPATH, \"//button[contains(@class, 'page-bar-type-button btn btn-lg ng-star-inserted') and text()='100']\"))\n",
        "    )\n",
        "    hundred_button.click()\n",
        "    time.sleep(5)\n",
        "\n",
        "    # Variable to store bond links\n",
        "    all_bond_links = []\n",
        "    # Get total number of pages\n",
        "    page_buttons = driver.find_elements(\n",
        "        By.XPATH,\n",
        "        \"//button[contains(@class, 'page-bar-type-button page-bar-type-button-width-auto btn btn-lg ng-star-inserted') and not(@disabled)]\",\n",
        "    )\n",
        "    page_limit = 356 # Limit to 1000 bonds for now\n",
        "    total_pages = min(\n",
        "        int(page_buttons[-1].text.strip()), page_limit or float(\"inf\")\n",
        "    )\n",
        "    print(f\"Total pages varaible: {total_pages}\")\n",
        "    print(f\"Total pages shown on website: {page_buttons[-1].text.strip()}\")\n",
        "\n",
        "    for page in range(1, total_pages + 1):\n",
        "        try:\n",
        "            if page != 1:\n",
        "                page_button = wait.until(\n",
        "                    EC.element_to_be_clickable((By.XPATH, f\"//button[contains(@class, 'page-bar-type-button page-bar-type-button-width-auto btn btn-lg ng-star-inserted') and text()='{page}']\"))\n",
        "                )\n",
        "                page_button.click()\n",
        "                time.sleep(10)\n",
        "            # Wait for page to full load\n",
        "            wait.until(EC.presence_of_element_located((By.XPATH, \"//div[@_ngcontent-boerse-frankfurt-c151]\")))\n",
        "\n",
        "            page_source = driver.page_source\n",
        "            soup = BeautifulSoup(page_source, \"html.parser\")\n",
        "            bond_links = extract_bond_links(soup)\n",
        "            all_bond_links.extend(bond_links)\n",
        "            print(f\"Page {page} done\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error at the page {page}: {e}\")\n",
        "            break\n",
        "\n",
        "    # Collecter les static data pour chaque obligation\n",
        "    static_bonds_data = []\n",
        "    print(f\"preview of bond links: {all_bond_links}\")\n",
        "\n",
        "    # getting bond data now\n",
        "    # Base URL\n",
        "    base_url = \"https://www.boerse-frankfurt.de\"\n",
        "    full_bond_links = []\n",
        "\n",
        "    for link in all_bond_links:  # all_bonds_links should already be collected earlier\n",
        "        full_url = base_url + link\n",
        "        full_bond_links.append(full_url)\n",
        "\n",
        "    # Iterate through each bond link\n",
        "    # for link in all_bond_links[:1000]:  # all_bonds_links should already be collected earlier\n",
        "    #     full_url = base_url + link\n",
        "    #     print(f\"Processing bond URL: {full_url}\")\n",
        "    #     bond_data = extract_bond_data(driver, full_url)\n",
        "    #     static_bonds_data.append(bond_data)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Critical error: {e}\")\n",
        "    # add screenshot\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    screenshot_path = f\"error_screenshot_{timestamp}.png\"\n",
        "    driver.save_screenshot(screenshot_path)\n",
        "\n",
        "# Export the DataFrame to a CSV file even if errors occur\n",
        "finally:\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    # Close the WebDriver\n",
        "    # save data\n",
        "    df = pd.DataFrame(full_bond_links)\n",
        "    df.to_csv(\"raw_all_bond_links.csv\", index=False)\n",
        "    driver.quit()"
      ],
      "metadata": {
        "id": "qcFTPXYlI5_6"
      },
      "id": "qcFTPXYlI5_6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head())\n",
        "print(df.shape)\n",
        "print(df.info())"
      ],
      "metadata": {
        "id": "Xdw4B3ZnKA4f"
      },
      "id": "Xdw4B3ZnKA4f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Getting Static Data for Bond_Dictionary"
      ],
      "metadata": {
        "id": "ie6OPzseo8V2"
      },
      "id": "ie6OPzseo8V2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "file path: C:\\Users\\Alex\\Documents\\GitHub\\EGR-Empirical-Project\\data\\Static_data\\bond_dictionary\\bond_dictionary_cleaned\n",
        "\n",
        "we re-use the above static data web scraping procedure to get the static data for only the bonds in our bond dictionary. making sure to also get the WKN to merge with our price data"
      ],
      "metadata": {
        "id": "y5Ey1wzKo_5o"
      },
      "id": "y5Ey1wzKo_5o"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the URL of the raw CSV file on GitHub\n",
        "url = \"https://raw.githubusercontent.com/Fijiman001/EGR-Empirical-Project/refs/heads/main/data/Static_data/bond_dictionary/bond_dictionary_cleaned.csv\"\n",
        "\n",
        "bond_dictionary = pd.read_csv(url)\n",
        "all_bond_links = bond_dictionary.iloc[:, 0].tolist()\n",
        "all_bond_links = all_bond_links[:20] # limit to 20 bonds to try\n",
        "print(len(all_bond_links))\n",
        "print(all_bond_links[:2])"
      ],
      "metadata": {
        "id": "pWVlkKHApOqZ"
      },
      "id": "pWVlkKHApOqZ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multi"
      ],
      "metadata": {
        "id": "r1wQ2lkovlbx"
      },
      "id": "r1wQ2lkovlbx"
    },
    {
      "cell_type": "code",
      "source": [
        "from multiprocessing import Pool\n",
        "import logging\n",
        "from tqdm import tqdm\n",
        "\n",
        "logger = logging.getLogger('selenium')\n",
        "logger.setLevel(logging.ERROR)\n",
        "\n",
        "driver = None # set later\n",
        "\n",
        "def get_driver():\n",
        "    # Check if Chromedriver is available on system path\n",
        "    shutil.which(\"chromedriver\")\n",
        "\n",
        "    # Configuration de Selenium WebDriver\n",
        "    options = webdriver.ChromeOptions()\n",
        "    options.add_argument(\"--headless\")\n",
        "    options.add_argument(\"--no-sandbox\")\n",
        "    options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "    # Initialisation de driver\n",
        "    driver = webdriver.Chrome(options=options)\n",
        "    url = \"https://www.boerse-frankfurt.de/anleihen/most-traded\"\n",
        "    return driver\n",
        "\n",
        "def init_child_process():\n",
        "    # set the global 'driver' variable\n",
        "    # so that calls to `scrape_bond` have access to it\n",
        "    # without creating a new driver for each bond\n",
        "    global driver\n",
        "    driver = get_driver()\n",
        "\n",
        "# getting bond data for only this URL\n",
        "def scrape_bond(url):\n",
        "      # start driver\n",
        "      assert driver is not None, \"Child process init did not happen\"\n",
        "      driver.get(url)\n",
        "      wait = WebDriverWait(driver, 5)\n",
        "      # Cooking handler\n",
        "      try:\n",
        "          cookie_button = WebDriverWait(driver, 5).until(\n",
        "              EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Decline')]\"))\n",
        "          )\n",
        "          cookie_button.click()\n",
        "          # print(\"Cookie banner handled successfully (Declined).\")\n",
        "      except TimeoutException:\n",
        "          # print(\"Cookie banner not found. Skipping...\")\n",
        "          None\n",
        "\n",
        "      # print(f\"Processing bond URL: {url}\")\n",
        "      bond_data = extract_bond_data(driver, url)\n",
        "      return bond_data\n",
        "\n",
        "# returns (result, err)\n",
        "def child_task(url, retries=3):\n",
        "    try:\n",
        "        result = scrape_bond(url)\n",
        "    except KeyboardInterrupt:\n",
        "        raise\n",
        "    except Exception as e:\n",
        "        if retries > 0:\n",
        "            time.sleep(2**(3-retries))\n",
        "            return child_task(url, retries-1)\n",
        "        else:\n",
        "          print(f\"Critical error: {e}\")\n",
        "          # add screenshot\n",
        "          timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "          screenshot_path = f\"error_screenshot_{timestamp}.png\"\n",
        "          driver.save_screenshot(screenshot_path)\n",
        "          return (None, e)\n",
        "    else:\n",
        "        return (result, None)\n",
        "\n",
        "num_processes = 10 # os.cpu_count() == 2\n",
        "with Pool(num_processes, initializer=init_child_process) as p:\n",
        "    results_with_error = p.map(child_task, all_bond_links)\n",
        "\n",
        "# ignore errors\n",
        "results = []\n",
        "for (result, err) in results_with_error:\n",
        "    if err is None:\n",
        "        results.append(result)\n",
        "\n",
        "results[0]"
      ],
      "metadata": {
        "id": "C4B0X8-uvnNn",
        "collapsed": true
      },
      "id": "C4B0X8-uvnNn",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "# Close the WebDriver\n",
        "# save data\n",
        "df = pd.DataFrame(results)\n",
        "# processed_df = process_bond_dataframe(df)\n",
        "# csv_file = f\"Static_bond_data{timestamp}.csv\"\n",
        "# processed_df.to_csv(csv_file, index=False)\n",
        "df.to_csv(f\"raw_static_data{timestamp}.csv\", index=False)\n",
        "print(f\"Data saved to raw_static_data{timestamp}.csv\")"
      ],
      "metadata": {
        "id": "1RjaQ7DTz1Gx"
      },
      "id": "1RjaQ7DTz1Gx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Singel driver - takes very long (~10 hours) - Multiprocessor below"
      ],
      "metadata": {
        "id": "pNrdmk4S4dgp"
      },
      "id": "pNrdmk4S4dgp"
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if Chromedriver is available on system path\n",
        "shutil.which(\"chromedriver\")\n",
        "\n",
        "# Configuration de Selenium WebDriver\n",
        "options = webdriver.ChromeOptions()\n",
        "options.add_argument(\"--headless\")\n",
        "options.add_argument(\"--no-sandbox\")\n",
        "options.add_argument(\"--disable-dev-shm-usage\")\n",
        "\n",
        "# Initialisation de driver\n",
        "driver = webdriver.Chrome(options=options)\n",
        "url = \"https://www.boerse-frankfurt.de/anleihen/most-traded\"\n",
        "# url = \"https://www.boerse-frankfurt.de/anleihen/green-bonds\"\n",
        "\n",
        "# Script principal\n",
        "try:\n",
        "    # start driver\n",
        "    driver.get(url)\n",
        "    wait = WebDriverWait(driver, 5)\n",
        "\n",
        "    try:\n",
        "        cookie_button = WebDriverWait(driver, 5).until(\n",
        "            EC.element_to_be_clickable((By.XPATH, \"//button[contains(text(), 'Decline')]\"))\n",
        "        )\n",
        "        cookie_button.click()\n",
        "        print(\"Cookie banner handled successfully (Declined).\")\n",
        "    except TimeoutException:\n",
        "        print(\"Cookie banner not found. Skipping...\")\n",
        "\n",
        "    # Collecter les static data pour chaque obligation\n",
        "    static_bonds_data = []\n",
        "    print(f\"preview of bond links: {all_bond_links}\")\n",
        "\n",
        "    # Iterate through each bond link\n",
        "    for link in all_bond_links:  # we loop over all our links\n",
        "        print(f\"Processing bond URL: {link}\")\n",
        "        bond_data = extract_bond_data(driver, link)\n",
        "        static_bonds_data.append(bond_data)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Critical error: {e}\")\n",
        "    # add screenshot\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    screenshot_path = f\"error_screenshot_{timestamp}.png\"\n",
        "    driver.save_screenshot(screenshot_path)\n",
        "\n",
        "# Export the DataFrame to a CSV file even if errors occur\n",
        "finally:\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "    # Close the WebDriver\n",
        "    # save data\n",
        "    df = pd.DataFrame(static_bonds_data)\n",
        "    # processed_df = process_bond_dataframe(df)\n",
        "    # csv_file = f\"Static_bond_data{timestamp}.csv\"\n",
        "    # processed_df.to_csv(csv_file, index=False)\n",
        "    df.to_csv(f\"raw_static_data{timestamp}.csv\", index=False)\n",
        "    print(f\"Data saved to {csv_file}\")\n",
        "    driver.quit()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "s-4DYQjypoO6"
      },
      "id": "s-4DYQjypoO6",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "xFDFhNkXJUZD",
        "tcxbq29DI2bi"
      ],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}